require(zoo)
print("hello world!")
require(zoo)
require(data.table)
unemp<- fread("UNRATE.csv")
unemp<- fread("C:/Users/jung6/Downloads/UNRATE.csv")
unemp[, Date := as.Date(DATE)] > setkey(uenemp, DATE)
require(zoo)
require(data.table)
print("hello world!")
unemp<- fread("C:/Users/jung6/Downloads/UNRATE.csv")
unemp[, Date := as.Date(DATE)] > setkey(uenemp, DATE)
unemp[, Date := as.Date(DATE)] > setkey(unemp, DATE)
## 임의로 누락된 데이터로 구성된 데이터셋 생성
rand.unemp.idx <-sample(1:nrow(unemp), .1*nrow(unemp))
rand.unemp <-unemp[-rand.unemp.idx]
## 실업률이 높을 대 누락될 가능성이 더 높은
## 데이터로 구성된 데이터셋 생성
high.unemp.idx <- which(unemp$UNRATE > 8)
num.to.select<-.2*length(high.unemp.idx, )
num.to.select<-.2*length(high.unemp.idx)
high.unemp.idx <-sample(high,unemp.idx, )
high.unemp.idx <-sample(high.unemp.idx, )
bias.unemp <- unemp[-high.unemp.idx]
all.dates <-seq(from = unemp$DATE[1], to = tail(unemp$DATE, 1), by = "months")
rand.unemp = rand.unemp[J(all.dates), roll=0]
bias.unemp = bias.unemp[J(all.dates), roll=0]
rand.unemp[, rpt :=is.na(UNRATE)]
## 포워드 필: 누락 값 발생 직전 값으로 누락 값을 채우는 간단한 방법
rand.unemp[, impute.ff:=na.locf(UNRATE, na.rm = FALSE)]
bias.unemp[, impute.ff := na.locf(UNRATE, na.rm = FALSE)]
## 평평한 부분을 보여주는 샘플 그래프
unemp[350:400, plot (DATE, UnRATE, col=1, lwd=2, type='b')]
## 평평한 부분을 보여주는 샘플 그래프
unemp[350:400, plot (DATE, UNRATE, col=1, lwd=2, type='b')]
rand.unemp[350:400, lines (DATE, impute.ff, col=2, lwd=2, lty=2)]
rand.unemp[350:400][rpt==TRUE, points(DATE, impute.ff, col=2, pch=6, cex=2)]
### 사전관찰이 없는 롤링 평균
rand.unemp[, impute.rm.nolookahead :=rollapply(c(NA, NA, UNRATE), 3,
function(x){
if (!is.na(x[3])) x[3] else mean(x, na.rm=TRUE)
})]
bias.unemp[, impute.rm.nolookahead :=rollapply(c(NA, NA, UNRATE), 3,
function(x){
if (!is.na(x[3])) x[3] else mean(x, na.rm=TRUE)
})]
### 사전 관찰이 포함된 롤링 평균
### 사전 관찰이 포함되므로 누락 데이터의 전후 데이터를 고려해 추정
### zoo 패키지의roll apply()기능을 통해 롤링 윈도우 구현
rand.unemp[, complete.rm := rollapply(c(NA, UNRATE, NA), 3,
function(x){
if (!is.na(x[2])) x[2]
else mean(x, na.rm = TRUE)
})]
## 보간법
use.idx = 150:200
unemp[use.idx, plot(DATE, UNRATE, col = 1, type = 'b')]
rand.unemp[use.idx, lines(DATE, impute.rm.nolookahead, col = 2)]
rand.unemp[use.idx][rpt == TRUE, points(DATE, impute.rm.nolookahead, col = 2, lwd = 3)]
rand.unemp[use.idx, lines(DATE, impute.rm.lookahead, col = 3)]
rand.unemp[use.idx][rpt == TRUE, points(DATE, impute.rm.lookahead, col = 3, lwd = 3)]
## 보간법
## linear interpolation
rand.unemp[, impute.li := na.approx(UNRATE)]
bias.unemp[, impute.li := na.approx(UNRATE)]
## polynomial interpolation
rand.unemp[, impute.sp := na.spline(UNRATE)]
bias.unemp[, impute.sp := na.spline(UNRATE)]
use.idx = 90:120
unemp[use.idx, plot(DATE, UNRATE, col = 1, type = 'b')]
rand.unemp[use.idx, lines(DATE, impute.li, col = 2, lwd= 2, lty = 2)]
rand.unemp[use.idx, lines(DATE, impute.li, col = 3, lwd= 2, lty = 3)]
require(zoo)
require(data.table)
require(zoo)
require(data.table)
print("hello world!")
unemp<- fread("C:/Users/jung6/Downloads/UNRATE.csv")
unemp[, Date := as.Date(DATE)] > setkey(unemp, DATE)
## 임의로 누락된 데이터로 구성된 데이터셋 생성
rand.unemp.idx <-sample(1:nrow(unemp), .1*nrow(unemp))
rand.unemp <-unemp[-rand.unemp.idx]
## 실업률이 높을 대 누락될 가능성이 더 높은
## 데이터로 구성된 데이터셋 생성
high.unemp.idx <- which(unemp$UNRATE > 8)
num.to.select<-.2*length(high.unemp.idx)
high.unemp.idx <-sample(high.unemp.idx, )
bias.unemp <- unemp[-high.unemp.idx]
all.dates <-seq(from = unemp$DATE[1], to = tail(unemp$DATE, 1), by = "months")
rand.unemp = rand.unemp[J(all.dates), roll=0]
bias.unemp = bias.unemp[J(all.dates), roll=0]
rand.unemp[, rpt :=is.na(UNRATE)]
## 포워드 필: 누락 값 발생 직전 값으로 누락 값을 채우는 간단한 방법
rand.unemp[, impute.ff:=na.locf(UNRATE, na.rm = FALSE)]
bias.unemp[, impute.ff := na.locf(UNRATE, na.rm = FALSE)]
## 평평한 부분을 보여주는 샘플 그래프
###동그란 선
unemp[350:400, plot (DATE, UNRATE, col=1, lwd=2, type='b')]
### 붉은 점선
rand.unemp[350:400, lines (DATE, impute.ff, col=2, lwd=2, lty=2)]
### 세모
rand.unemp[350:400][rpt==TRUE, points(DATE, impute.ff, col=2, pch=6, cex=2)]
### 사전관찰이 없는 롤링 평균
rand.unemp[, impute.rm.nolookahead :=rollapply(c(NA, NA, UNRATE), 3,
function(x){
if (!is.na(x[3])) x[3] else mean(x, na.rm=TRUE)
})]
bias.unemp[, impute.rm.nolookahead :=rollapply(c(NA, NA, UNRATE), 3,
function(x){
if (!is.na(x[3])) x[3] else mean(x, na.rm=TRUE)
})]
### 사전 관찰이 포함된 롤링 평균
### 사전 관찰이 포함되므로 누락 데이터의 전후 데이터를 고려해 추정
### zoo 패키지의roll apply()기능을 통해 롤링 윈도우 구현
rand.unemp[, complete.rm := rollapply(c(NA, UNRATE, NA), 3,
function(x){
if (!is.na(x[2])) x[2]
else mean(x, na.rm = TRUE)
})]
## 보간법 -> 설명
## linear interpolation
rand.unemp[, impute.li := na.approx(UNRATE)]
bias.unemp[, impute.li := na.approx(UNRATE)]
## polynomial interpolation
rand.unemp[, impute.sp := na.spline(UNRATE)]
bias.unemp[, impute.sp := na.spline(UNRATE)]
use.idx = 90:120
unemp[use.idx, plot(DATE, UNRATE, col = 1, type = 'b')]
rand.unemp[use.idx, lines(DATE, impute.li, col = 2, lwd= 2, lty = 2)]
rand.unemp[use.idx, lines(DATE, impute.li, col = 3, lwd= 2, lty = 3)]
rand.unemp[use.idx, lines(DATE, impute.sp, col = 3, lwd= 2, lty = 3)]
sort(rand.unemp[ , lapply(.SD, function(x) mean((x - unemp$UNRATE)^2, na.rm = TRUE)),
.SDcols = c("impute.ff", "impute.rm.nolookahead", "impute.rm.lookahead", "impute.li", "impute.sp")])
sort(rand.unemp[ , lapply(.SD, function(x) mean((x - unemp$UNRATE)^2, na.rm = TRUE)),
.SDcols = c("impute.ff", "impute.rm.nolookahead", "impute.rm.lookahead", "impute.li", "impute.sp")])
sort(bias.unemp[ , lapply(.SD, function(x) mean((x - unemp$UNRATE)^2, na.rm = TRUE)),
.SDcols = c("impute.ff", "impute.rm.nolookahead", "impute.rm.lookahead", "impute.li", "impute.sp")])
sort(rand.unemp[ , lapply(.SD, function(x) mean((x - unemp$UNRATE)^2, na.rm = TRUE)),
.SDcols = c("impute.ff", "impute.rm.nolookahead", "impute.rm.lookahead", "impute.li", "impute.sp")])
sort(bias.unemp[ , lapply(.SD, function(x) mean((x - unemp$UNRATE)^2, na.rm = TRUE)),
.SDcols = c("impute.ff", "impute.rm.nolookahead", "impute.rm.lookahead", "impute.li", "impute.sp")])
# 평균제곱오차MSE 비교를 통한 가장 좋은 대치법 찾기
sort(rand.unemp[ , lapply(.SD, function(x) mean((x - unemp$UNRATE)^2, na.rm = TRUE)),
.SDcols = c("impute.ff", "impute.rm.lookahead", "impute.rm.nolookahead", "impute.li", "impute.sp")])
sort(bias.unemp[ , lapply(.SD, function(x) mean((x - unemp$UNRATE)^2, na.rm = TRUE)),
.SDcols = c("impute.ff", "impute.rm.lookahead", "impute.rm.nolookahead", "impute.li", "impute.sp")])
sort(bias.unemp[ , lapply(.SD, function(x) mean((x - unemp$UNRATE)^2, na.rm = TRUE)),
.SDcols = c("impute.ff", "impute.rm.nolookahead", "impute.li", "impute.sp")]) ## "impute.rm.lookahead",
# 평균제곱오차MSE 비교를 통한 가장 좋은 대치법 찾기
sort(rand.unemp[ , lapply(.SD, function(x) mean((x - unemp$UNRATE)^2, na.rm = TRUE)),
.SDcols = c("impute.ff", "impute.rm.nolookahead", "impute.li", "impute.sp")]) ## "impute.rm.lookahead",
# 다운샘플링: 데이터의 빈도를 줄이는 모든 순간.
## 원본 데이터의 시간 단위가 실용적이지 않은 경우: 자주 -> 덜 자주
## 계절 주기의 특정 부분에 집중하는 경우: 전반적 계절성보다 특정 계절에 초점을 맞추는 경우
unemp[seq.int(from = 2, to = nrow(unemp), by = 12)]
## 3) 더 낮은 빈도의 데이터에 맞추는 경우
unemp[, mean(UNRATE), by = format(DATE, "%Y")]
# 업샘플링: 더 자주 측정하거나 조밀한 시간의 데이터 얻기 -> 더 많은 시간 레이블이 추가되지만, 정보가 추가되지는 않음
## 1) 시게열이 불규칙한 상황 -> 누락 값을 채웠던 롤링 조인 등
all.dates<- seq(from = unemp$DATE[1], to = tail(unemp$DATE, 1), by = "months")
rand.unemp = rand.unemp[J(all.dates), roll=0]
all.dates
rand.unemp = rand.unemp[J(all.dates), roll=0]
## 2) 입력이 서로 다른 비녿로 샘플링된 상황
daily.unemployment = unemp[J(all.dates), roll = 31]
daily.unemployment
require(zoo)
require(zoo)
require(data.table)
print("hello world!")
unemp<- fread("C:/Users/jung6/Downloads/UNRATE.csv")
unemp[, Date := as.Date(DATE)] > setkey(unemp, DATE)
## 임의로 누락된 데이터로 구성된 데이터셋 생성
rand.unemp.idx <-sample(1:nrow(unemp), .1*nrow(unemp))
rand.unemp <-unemp[-rand.unemp.idx]
## 실업률이 높을 대 누락될 가능성이 더 높은
## 데이터로 구성된 데이터셋 생성
high.unemp.idx <- which(unemp$UNRATE > 8)
num.to.select<-.2*length(high.unemp.idx)
high.unemp.idx <-sample(high.unemp.idx, )
bias.unemp <- unemp[-high.unemp.idx]
all.dates <-seq(from = unemp$DATE[1], to = tail(unemp$DATE, 1), by = "months")
rand.unemp = rand.unemp[J(all.dates), roll=0]
bias.unemp = bias.unemp[J(all.dates), roll=0]
rand.unemp[, rpt :=is.na(UNRATE)]
## 포워드 필: 누락 값 발생 직전 값으로 누락 값을 채우는 간단한 방법
rand.unemp[, impute.ff:=na.locf(UNRATE, na.rm = FALSE)]
bias.unemp[, impute.ff := na.locf(UNRATE, na.rm = FALSE)]
## 평평한 부분을 보여주는 샘플 그래프
###동그란 선
unemp[350:400, plot (DATE, UNRATE, col=1, lwd=2, type='b')]
### 붉은 점선
rand.unemp[350:400, lines (DATE, impute.ff, col=2, lwd=2, lty=2)]
### 세모
rand.unemp[350:400][rpt==TRUE, points(DATE, impute.ff, col=2, pch=6, cex=2)]
### 사전관찰이 없는 롤링 평균
rand.unemp[, impute.rm.nolookahead :=rollapply(c(NA, NA, UNRATE), 3,
function(x){
if (!is.na(x[3])) x[3] else mean(x, na.rm=TRUE)
})]
bias.unemp[, impute.rm.nolookahead :=rollapply(c(NA, NA, UNRATE), 3,
function(x){
if (!is.na(x[3])) x[3] else mean(x, na.rm=TRUE)
})]
### 사전 관찰이 포함된 롤링 평균
### 사전 관찰이 포함되므로 누락 데이터의 전후 데이터를 고려해 추정
### zoo 패키지의roll apply()기능을 통해 롤링 윈도우 구현
rand.unemp[, complete.rm := rollapply(c(NA, UNRATE, NA), 3,
function(x){
if (!is.na(x[2])) x[2]
else mean(x, na.rm = TRUE)
})]
## 선 형보간법linear interpolation
### 누락된 데이터가 주변 데이터에 선형적 일관성을 가도록 제한
### 시간에 따라 시스템이 동작하는 방식 미리 알고 적용할 때 유용(선험적)
rand.unemp[, impute.li := na.approx(UNRATE)]
bias.unemp[, impute.li := na.approx(UNRATE)]
## 다항식 보간법polynomial interpolation
rand.unemp[, impute.sp := na.spline(UNRATE)]
bias.unemp[, impute.sp := na.spline(UNRATE)]
use.idx = 90:120
unemp[use.idx, plot(DATE, UNRATE, col = 1, type = 'b')]
rand.unemp[use.idx, lines(DATE, impute.li, col = 2, lwd= 2, lty = 2)] #선형 보간법
rand.unemp[use.idx, lines(DATE, impute.sp, col = 3, lwd= 2, lty = 3)] #스플라인 보간법
# 평균제곱오차MSE 비교를 통한 가장 좋은 대치법 찾기
sort(rand.unemp[ , lapply(.SD, function(x) mean((x - unemp$UNRATE)^2, na.rm = TRUE)),
.SDcols = c("impute.ff", "impute.rm.nolookahead", "impute.li", "impute.sp")]) ## "impute.rm.lookahead",
sort(bias.unemp[ , lapply(.SD, function(x) mean((x - unemp$UNRATE)^2, na.rm = TRUE)),
.SDcols = c("impute.ff", "impute.rm.nolookahead", "impute.li", "impute.sp")]) ## "impute.rm.lookahead",
# 다운샘플링: 데이터의 빈도를 줄이는 모든 순간.
## 1) 원본 데이터의 시간 단위가 실용적이지 않은 경우: 자주 -> 덜 자주
## 2) 계절 주기의 특정 부분에 집중하는 경우: 전반적 계절성보다 특정 계절에 초점을 맞추는 경우
unemp[seq.int(from = 2, to = nrow(unemp), by = 12)] # 전체 12개월 중 2월만 뽑음
## 3) 더 낮은 빈도의 데이터에 맞추는 경우
unemp[, mean(UNRATE), by = format(DATE, "%Y")] # 연도별 평균
# 업샘플링: 더 자주 측정하거나 조밀한 시간의 데이터 얻기 -> 더 많은 시간 레이블이 추가되지만, 정보가 추가되지는 않음
## 1) 시게열이 불규칙한 상황 -> 누락 값을 채웠던 롤링 조인 등
all.dates<- seq(from = unemp$DATE[1], to = tail(unemp$DATE, 1), by = "months")
all.dates
rand.unemp = rand.unemp[J(all.dates), roll=0]
## 2) 입력이 서로 다른 빈도로 샘플링된 상황
daily.unemployment = unemp[J(all.dates), roll = 31] # 월별 데이터를 일자별로 각각 입력(48년 1월은 모두 일자 상관 없이 3.4인 등)
daily.unemployment
# 2.4.3. 데이터 평활Smoothing
# 2.4.3. 데이터 평활Smoothing
# 목적:
# 2.4.3. 데이터 평활Smoothing
# 목적:
# 1) 데이터 준비: 이상치가 너무 큰 경우
# 2.4.3. 데이터 평활Smoothing
# 목적:
# 1) 데이터 준비: 이상치가 너무 큰 경우
# 2) 특징feature 생성: 몇몇 지표로 요약하는 등
# 2.4.3. 데이터 평활Smoothing
# 목적:
# 1) 데이터 준비: 이상치가 너무 큰 경우
# 2) 특징feature 생성: 몇몇 지표로 요약하는 등
# 3) 예측: 평활된 특징을 통해 예측하는 평균회귀
## 지수평활: 시점마다 데이터를 다르게 취급할 때->최근 데이터에 가중치
## 지수평활: 시점마다 데이터를 다르게 취급할 때->최근 데이터에 가중치
## 91페이지 수식, 106페이지 논문 참고
# 2.5 계절성 데이터
plot(stl(AirPassengers, "periodic"))
# 3.1.1. 도표 그리기
head(EuStockMarkets)
# 3.1.1. 도표 그리기
head(EuStockMarkets)
## 그래프 그리기
plot(EuStockMarkets)
class(EuStockMarkets)
## frequency(): 데이터 연간 빈도
frequency(EuStockMarkets)
## start(), end(): 데이터 시작과 끝
start(EuStockMarkets)
end(EuStockMarkets)
## window(): 시간의 한 부분 범위
window(EuStockMarkets, start = 1997, end = 1998)
### 3.1.2 히스토그램
hist(EuStockMarkets[, "SMI"], 30)
hist(dist(EuStockMarkets[, "SMI"], 30))
hist(diff(EuStockMarkets[, "SMI"], 30))
plot(     EuStockMarkets[, "SMI"],       EuStockMarkets[, "DAX"])
plot(diff(EuStockMarkets[, "SMI"]), diff(EuStockMarkets[, "DAX"]))
# lag함수 적용
plot(lag(diff(EuStockMarkets[, "SMI"]), 1),
diff(EuStockMarkets[, "DAX"]))
require(zoo)
## 데이터 출력
head(EuStockMarkets)
## 그래프 그리기
plot(EuStockMarkets)
class(EuStockMarkets)
## frequency(): 데이터 연간 빈도
frequency(EuStockMarkets)
## start(), end(): 데이터 시작과 끝
start(EuStockMarkets)
end(EuStockMarkets)
## window(): 시간의 한 부분 범위
window(EuStockMarkets, start = 1997, end = 1998)
### 3.1.2 히스토그램
hist(     EuStockMarkets[, "SMI"], 30)  # 원본데이터 히스토그램은 넓게 퍼지고, 정규분포X
hist(diff(EuStockMarkets[, "SMI"], 30)) # 인접 데이터의 차diff를 구하면 정규분포O
plot(     EuStockMarkets[, "SMI"],       EuStockMarkets[, "DAX"])
plot(diff(EuStockMarkets[, "SMI"]), diff(EuStockMarkets[, "DAX"]))
# lag함수 적용
plot(lag(diff(EuStockMarkets[, "SMI"]), 1),
diff(EuStockMarkets[, "DAX"]))
### 정규분포를 따르는 난수 100개 추출
x<- rnorm(n=100, mean=0, sd=10) + 1:100
### rep함수로 1/n 값을 n번 반복하는 배열을 만드는 함수
mn<- function(n) rep(1/n, n)
plot(x, type = 't', lwd = 1)
### R의 filter함수로 롤링 평균 계산. 5, 50개 단위
lines(filter(x, mn( 5)), col = 2, lwd = 3, lty = 2)
lines(filter(x, mn( )0), col = 3, lwd = 3, lty = 3)
lines(filter(x, mn(50)), col = 3, lwd = 3, lty = 3)
plot(x, type = 'l', lwd = 1)
### R의 filter함수로 롤링 평균 계산. 5, 50개 단위
lines(filter(x, mn( 5)), col = 2, lwd = 3, lty = 2)
lines(filter(x, mn(50)), col = 3, lwd = 3, lty = 3)
require(zoo)
### x를 zoo 객체로 만들어 각 데이터 인덱싱
### rollapply: 데이터, 윈도우 크기, 적용 함수, 롤링 적용방향, 윈도우 크기만큼 데이터가 없어도 적용할지 등 인수 지정
f1<- rollapply(zoo(x), 20, function(w) min(w), align = "left", partial = TRUE)
f2<- rollapply(zoo(x), 20, function(w) min(w), align = "right", partial = TRUE)
plot(x, lwd=1, type='l')
lines(f1, col=2, lty=2)
lines(f1, col=2, lwd=3, lty=2)
lines(f2, col=3, lwd=3, lty=3)
