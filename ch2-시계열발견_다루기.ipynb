{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter2: 시계열 데이터 수집 및 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번 장에서는 시계열 데이터 수집, 전처리하는 방법을 배운다.\n",
    "\n",
    "### 목차\n",
    "- 온라인 저장소에서 시계열 데이터 찾기\n",
    "- 시계열을 고려하지 않고 수집된 데이터에서 시계열 데이터 수집 및 전처리\n",
    "- timestamp 다루는 방법\n",
    "\n",
    "\n",
    "### 2.1. 시계열 데이터 찾기\n",
    "\n",
    "시계열 데이터는 목적에 따라 크게\n",
    "\n",
    "1. 학습, 실험 목적으로 생성된 데이터\n",
    "    - [UCI 머신러닝 저장소 - 시계열](https://archive.ics.uci.edu/ml/datasets.php?format=&task=&att=&area=&numAtt=&numIns=&type=ts&sort=nameUp&view=table): 결근, 공기질 등.\n",
    "    - [UEA, UCR 시계열 분류 저장소](https://perma.cc/56Q5-YPNT): [요가 동작 분류 작업](https://perma.cc/U6MU-2SCZ), [와인 데이터셋](https://perma.cc/Y34-UGMD) 등\n",
    "    - 정부 시계열 데이터셋: 미국 국립환경정보센터NCEI, 미국 노동통계국, 미국 질병통제에방센터CDC, 세인트루이스 연방준비은행, 한국 기상청 등. 경제와 기후, 범죄에 대한 정부 지출과 각 범죄율을 병렬로 다변량 시계열을 사용하면서 분석할 수 있다. 하지만 여러 요인이 작용하므로 학습용으로는 적합하지 않을 수 있음.\n",
    "    - [CompEngine](https://www.comp-engine.org/#!browse/category): 시계열 데이터를 스스로 조직화하는 데이터베이스.\n",
    "    - R의 Mcomp, M4comp2018 패키지, [CRAN 저장소](https://perma.cc/2694-D79K)의 시계열 데이터 섹션\n",
    "2. 시계열이 아닌 데이터에서 시계열 데이터 생성: timestamp를 시계열로 변환 및 결합\n",
    "    - timestamp가 찍힌 기록: 임의의 시점과 그 시점 이후의 시점 타임 스탬프(접근 등)으로 시간의 변화량을 모델링할 수 있음\n",
    "    - 시간 없는 측정으로 시간 대체: 데이터가 시간을 명시적으로 포함하지 않아도, 데이터의 숨은 논리로 유추할 수 있는 경우. 센서 주기 등\n",
    "    - 물리적 흔적: 디지털로 저장된 흔적을 이미지나 데이터베이스에 저장됨\n",
    "\n",
    "으로 나눌 수 있다.\n",
    "\n",
    "\n",
    "- 유의: 데이터에 구체적 '시간'이 없더라도, **일련의 정렬된 형태를 띈다면 시계열 적용 가능**\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. 흩어진 데이터를 시계열 데이터로 만들기\n",
    "\n",
    "NGO에서 시계열 분석을 한다고 할 때, SQL로도 충분히 시계열에 대한 현황 분석을 할 수 있다.\n",
    "- 메일을 읽었는지:  빈도, 응답 시간에 따라 메일 수신의 피로감 파악\n",
    "- 기부 멤버십 중단 경험: 시계열 기부 예측 \n",
    "- 거래 내역: 어떤 특정한 시점에 구매할지 예측\n",
    "\n",
    "하지만 보통 데이터베이스 스키마를 설계할 때, 시계열 분석을 고려하지 않아 따로 시계열을 수집하고 구성해야한다.\n",
    "\n",
    "아래 데이터의 시간 구분은 다음과 같다.\n",
    "- YearJoined: 연간 회원 상태\n",
    "- emails: 이메일 열람 관련 주간 누적 기록\n",
    "- donations: 기부가 이루어진 순간의 타임스탬프"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 정리\n",
    "\n",
    "1. **해결하고자 하는 문제에 맞는 형태로 데이터 간격 교정**\n",
    "2. **사전 관찰을 피하기 위해 timestamp를 사용하지 않는 방법 모색**\n",
    "3. **아무 일이 없더라도 관련된 모든 기간을 기록**\n",
    "4. **사전관찰을 피하기 위해 아직 알아서는 안되는 timestamp를 다시 한번 배제**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>userStats</th>\n",
       "      <th>yearJoined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>silver</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>silver</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>silver</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>bronze</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>silver</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user userStats  yearJoined\n",
       "0     0    silver        2014\n",
       "1     1    silver        2015\n",
       "2     2    silver        2016\n",
       "3     3    bronze        2018\n",
       "4     4    silver        2018"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YearJoined = pd.read_csv(\"https://raw.githubusercontent.com/PracticalTimeSeriesAnalysis/BookRepo/master/Ch02/data/year_joined.csv\")\n",
    "YearJoined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emailsOpened</th>\n",
       "      <th>user</th>\n",
       "      <th>week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015-06-29 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015-07-13 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015-07-20 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015-07-27 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015-08-03 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emailsOpened  user                 week\n",
       "0           3.0   1.0  2015-06-29 00:00:00\n",
       "1           2.0   1.0  2015-07-13 00:00:00\n",
       "2           2.0   1.0  2015-07-20 00:00:00\n",
       "3           3.0   1.0  2015-07-27 00:00:00\n",
       "4           1.0   1.0  2015-08-03 00:00:00"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails = pd.read_csv(\"https://raw.githubusercontent.com/PracticalTimeSeriesAnalysis/BookRepo/master/Ch02/data/emails.csv\")\n",
    "emails.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.0</td>\n",
       "      <td>2017-11-12 11:13:44</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50.0</td>\n",
       "      <td>2015-08-25 19:01:45</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25.0</td>\n",
       "      <td>2015-03-26 12:03:47</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50.0</td>\n",
       "      <td>2016-07-06 12:24:55</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50.0</td>\n",
       "      <td>2016-05-11 18:13:04</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   amount            timestamp  user\n",
       "0    25.0  2017-11-12 11:13:44   0.0\n",
       "1    50.0  2015-08-25 19:01:45   0.0\n",
       "2    25.0  2015-03-26 12:03:47   0.0\n",
       "3    50.0  2016-07-06 12:24:55   0.0\n",
       "4    50.0  2016-05-11 18:13:04   1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "donations = pd.read_csv(\"https://raw.githubusercontent.com/PracticalTimeSeriesAnalysis/BookRepo/master/Ch02/data/donations.csv\")\n",
    "donations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1000명의 모든 회원이 하나의 상태만 가진다. 따라서 year Joined는 가입연도와 현재 혹은 가입 당시의 상태를 나타낼 가능성이 높음. 정확하게 분석하려면 데이터 파이프라인을 알아야한다.\n",
    "\n",
    " - **사전관찰**: 과거 데이터 분석에 현재 회원의 상태를 적용하면 알 수 없는 시계열 모델에 무언가를 입력하는 꼴이 된다.\n",
    "    - 시계열에서 사전관찰: 미래의 어떤 사실을 안다는 의미로 사용. 데이터를 통해 실제로 알아야하는 시점보다 더 일찍 미래에 대한 사실을 발견. 미래에 일어난 일에 대한 정보가 과거 모델 초기 동작에 영향을 주는 방법. 자동화된 코드나 통게 테스트가 없어서 스스로 고민해야함.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yearJoined</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userStats</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           yearJoined\n",
       "userStats            \n",
       "1                1000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 28 page\n",
    "YearJoined.groupby('user').count().groupby('userStats').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 고려해야할 점\n",
    "    - 어떤 방식으로 시간을 표현했는지: 주wwek를 나눌 때 1.1로 나누는게 아니라 첫 월요일을 기준으로 하는 등.\n",
    "    - null 값이 있는지: **시계열에서는 null이 존재해야한다**. 아무일도 발생하지 않는 주 또한 데이터의 일부.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emailsOpened</th>\n",
       "      <th>user</th>\n",
       "      <th>week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [emailsOpened, user, week]\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails[emails.emailsOpened < 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 두 가지 가능성\n",
    "    1. null이 발생하지 않았거나, \n",
    "    2. 모든 회원이 이메일을 열람했다는 이벤트가 적어도 하나 존재\n",
    "\n",
    "하지만 모든 회원이 매주 이메일 열람은 가능성이 낮다. 따라서 특정 한 회원 데이터를 살펴보면서 판단 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emailsOpened</th>\n",
       "      <th>user</th>\n",
       "      <th>week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25464</th>\n",
       "      <td>1.0</td>\n",
       "      <td>998.0</td>\n",
       "      <td>2017-12-04 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25465</th>\n",
       "      <td>3.0</td>\n",
       "      <td>998.0</td>\n",
       "      <td>2017-12-11 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25466</th>\n",
       "      <td>3.0</td>\n",
       "      <td>998.0</td>\n",
       "      <td>2017-12-18 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25467</th>\n",
       "      <td>3.0</td>\n",
       "      <td>998.0</td>\n",
       "      <td>2018-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25468</th>\n",
       "      <td>3.0</td>\n",
       "      <td>998.0</td>\n",
       "      <td>2018-01-08 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25469</th>\n",
       "      <td>2.0</td>\n",
       "      <td>998.0</td>\n",
       "      <td>2018-01-15 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25470</th>\n",
       "      <td>3.0</td>\n",
       "      <td>998.0</td>\n",
       "      <td>2018-01-22 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25471</th>\n",
       "      <td>2.0</td>\n",
       "      <td>998.0</td>\n",
       "      <td>2018-01-29 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25472</th>\n",
       "      <td>3.0</td>\n",
       "      <td>998.0</td>\n",
       "      <td>2018-02-05 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25473</th>\n",
       "      <td>3.0</td>\n",
       "      <td>998.0</td>\n",
       "      <td>2018-02-12 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25474</th>\n",
       "      <td>3.0</td>\n",
       "      <td>998.0</td>\n",
       "      <td>2018-02-19 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25475</th>\n",
       "      <td>2.0</td>\n",
       "      <td>998.0</td>\n",
       "      <td>2018-02-26 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25476</th>\n",
       "      <td>2.0</td>\n",
       "      <td>998.0</td>\n",
       "      <td>2018-03-05 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25477</th>\n",
       "      <td>3.0</td>\n",
       "      <td>998.0</td>\n",
       "      <td>2018-03-12 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25478</th>\n",
       "      <td>2.0</td>\n",
       "      <td>998.0</td>\n",
       "      <td>2018-03-19 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25479</th>\n",
       "      <td>2.0</td>\n",
       "      <td>998.0</td>\n",
       "      <td>2018-03-26 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25480</th>\n",
       "      <td>3.0</td>\n",
       "      <td>998.0</td>\n",
       "      <td>2018-04-02 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25481</th>\n",
       "      <td>3.0</td>\n",
       "      <td>998.0</td>\n",
       "      <td>2018-04-09 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25482</th>\n",
       "      <td>3.0</td>\n",
       "      <td>998.0</td>\n",
       "      <td>2018-04-16 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25483</th>\n",
       "      <td>3.0</td>\n",
       "      <td>998.0</td>\n",
       "      <td>2018-04-30 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25484</th>\n",
       "      <td>3.0</td>\n",
       "      <td>998.0</td>\n",
       "      <td>2018-05-07 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25485</th>\n",
       "      <td>3.0</td>\n",
       "      <td>998.0</td>\n",
       "      <td>2018-05-14 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25486</th>\n",
       "      <td>3.0</td>\n",
       "      <td>998.0</td>\n",
       "      <td>2018-05-21 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25487</th>\n",
       "      <td>3.0</td>\n",
       "      <td>998.0</td>\n",
       "      <td>2018-05-28 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       emailsOpened   user                 week\n",
       "25464           1.0  998.0  2017-12-04 00:00:00\n",
       "25465           3.0  998.0  2017-12-11 00:00:00\n",
       "25466           3.0  998.0  2017-12-18 00:00:00\n",
       "25467           3.0  998.0  2018-01-01 00:00:00\n",
       "25468           3.0  998.0  2018-01-08 00:00:00\n",
       "25469           2.0  998.0  2018-01-15 00:00:00\n",
       "25470           3.0  998.0  2018-01-22 00:00:00\n",
       "25471           2.0  998.0  2018-01-29 00:00:00\n",
       "25472           3.0  998.0  2018-02-05 00:00:00\n",
       "25473           3.0  998.0  2018-02-12 00:00:00\n",
       "25474           3.0  998.0  2018-02-19 00:00:00\n",
       "25475           2.0  998.0  2018-02-26 00:00:00\n",
       "25476           2.0  998.0  2018-03-05 00:00:00\n",
       "25477           3.0  998.0  2018-03-12 00:00:00\n",
       "25478           2.0  998.0  2018-03-19 00:00:00\n",
       "25479           2.0  998.0  2018-03-26 00:00:00\n",
       "25480           3.0  998.0  2018-04-02 00:00:00\n",
       "25481           3.0  998.0  2018-04-09 00:00:00\n",
       "25482           3.0  998.0  2018-04-16 00:00:00\n",
       "25483           3.0  998.0  2018-04-30 00:00:00\n",
       "25484           3.0  998.0  2018-05-07 00:00:00\n",
       "25485           3.0  998.0  2018-05-14 00:00:00\n",
       "25486           3.0  998.0  2018-05-21 00:00:00\n",
       "25487           3.0  998.0  2018-05-28 00:00:00"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails[emails.user == 998]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일부 주가 누락됨. 17년 12.18. 이후 이메일 열람 기록이 없음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 수학적으로 주차 계산하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25488 entries, 0 to 25487\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   emailsOpened  25488 non-null  float64\n",
      " 1   user          25488 non-null  float64\n",
      " 2   week          25488 non-null  object \n",
      "dtypes: float64(2), object(1)\n",
      "memory usage: 597.5+ KB\n"
     ]
    }
   ],
   "source": [
    "emails.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "date_time_str_max = max(emails[emails.user == 998].week)\n",
    "date_time_str_min = min(emails[emails.user == 998].week)\n",
    "\n",
    "date_time_obj_max = datetime.datetime.strptime(date_time_str_max, '%Y-%m-%d %H:%M:%S')\n",
    "date_time_obj_min = datetime.datetime.strptime(date_time_str_min, '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "(date_time_obj_max - date_time_obj_min).days/7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails[emails.user == 998].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전체 26주 중 24개 데이터만 있는 것으로 보아 2개 누락. 물론 이는 한 명의 데이터이므로 다른 사람은 다를 수도 있다. null 값은 없지만, 아예 데이터가 수집되지 않은 주는 있다.\n",
    "\n",
    "- 왜 25가 아니고 26주?\n",
    "    - 마지막에 1을 더할지 말지 고민해야함\n",
    "    - 4월 7, 14, 21, 28 -> 4일\n",
    "    - (마지막 날 - 처음 날) / 7 = (28-7) / 7 = 3\n",
    "    - 처음, 혹은 마지막 날을 빼먹음. 따라서 1 더해주어야 함.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 판다스 multi index를 이용해 주차 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_idx = pd.MultiIndex.from_product((set(emails.week), set(emails.user)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex([('2018-03-19 00:00:00',   1.0),\n",
       "            ('2018-03-19 00:00:00',   3.0),\n",
       "            ('2018-03-19 00:00:00',   5.0),\n",
       "            ('2018-03-19 00:00:00',   6.0),\n",
       "            ('2018-03-19 00:00:00',   9.0),\n",
       "            ('2018-03-19 00:00:00',  10.0),\n",
       "            ('2018-03-19 00:00:00',  14.0),\n",
       "            ('2018-03-19 00:00:00',  16.0),\n",
       "            ('2018-03-19 00:00:00',  20.0),\n",
       "            ('2018-03-19 00:00:00',  21.0),\n",
       "            ...\n",
       "            ('2016-10-03 00:00:00', 973.0),\n",
       "            ('2016-10-03 00:00:00', 977.0),\n",
       "            ('2016-10-03 00:00:00', 982.0),\n",
       "            ('2016-10-03 00:00:00', 984.0),\n",
       "            ('2016-10-03 00:00:00', 987.0),\n",
       "            ('2016-10-03 00:00:00', 991.0),\n",
       "            ('2016-10-03 00:00:00', 992.0),\n",
       "            ('2016-10-03 00:00:00', 993.0),\n",
       "            ('2016-10-03 00:00:00', 995.0),\n",
       "            ('2016-10-03 00:00:00', 998.0)],\n",
       "           length=93247)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_email = emails.set_index(['week', 'user']).reindex(complete_idx, fill_value=0).reset_index()\n",
    "all_email.columns = ['week', 'user', 'emailsOpened']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>week</th>\n",
       "      <th>user</th>\n",
       "      <th>emailsOpened</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48509</th>\n",
       "      <td>2015-02-09 00:00:00</td>\n",
       "      <td>998.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22098</th>\n",
       "      <td>2015-02-16 00:00:00</td>\n",
       "      <td>998.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28566</th>\n",
       "      <td>2015-02-23 00:00:00</td>\n",
       "      <td>998.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45814</th>\n",
       "      <td>2015-03-02 00:00:00</td>\n",
       "      <td>998.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33956</th>\n",
       "      <td>2015-03-09 00:00:00</td>\n",
       "      <td>998.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18325</th>\n",
       "      <td>2018-04-30 00:00:00</td>\n",
       "      <td>998.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66296</th>\n",
       "      <td>2018-05-07 00:00:00</td>\n",
       "      <td>998.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59828</th>\n",
       "      <td>2018-05-14 00:00:00</td>\n",
       "      <td>998.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58750</th>\n",
       "      <td>2018-05-21 00:00:00</td>\n",
       "      <td>998.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85700</th>\n",
       "      <td>2018-05-28 00:00:00</td>\n",
       "      <td>998.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>173 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      week   user  emailsOpened\n",
       "48509  2015-02-09 00:00:00  998.0           0.0\n",
       "22098  2015-02-16 00:00:00  998.0           0.0\n",
       "28566  2015-02-23 00:00:00  998.0           0.0\n",
       "45814  2015-03-02 00:00:00  998.0           0.0\n",
       "33956  2015-03-09 00:00:00  998.0           0.0\n",
       "...                    ...    ...           ...\n",
       "18325  2018-04-30 00:00:00  998.0           3.0\n",
       "66296  2018-05-07 00:00:00  998.0           3.0\n",
       "59828  2018-05-14 00:00:00  998.0           3.0\n",
       "58750  2018-05-21 00:00:00  998.0           3.0\n",
       "85700  2018-05-28 00:00:00  998.0           3.0\n",
       "\n",
       "[173 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_email[all_email.user ==998].sort_values('week')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "998번 회원의 경우 가입 직후에 email을 열지 않았다. 0이 아닌 숫자가 나오기 이전 데이터를 null로 처리하는 방법은 다음과 같다.\n",
    "\n",
    "먼저 회원별로 처음 메일을 열기 시작한 시점을 알아보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>user</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015-06-29 00:00:00</td>\n",
       "      <td>2018-05-28 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2018-03-05 00:00:00</td>\n",
       "      <td>2018-04-23 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2017-06-05 00:00:00</td>\n",
       "      <td>2018-05-28 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2016-12-05 00:00:00</td>\n",
       "      <td>2018-05-28 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2016-07-18 00:00:00</td>\n",
       "      <td>2018-05-28 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>534</td>\n",
       "      <td>991.0</td>\n",
       "      <td>2016-10-24 00:00:00</td>\n",
       "      <td>2016-10-24 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>535</td>\n",
       "      <td>992.0</td>\n",
       "      <td>2015-02-09 00:00:00</td>\n",
       "      <td>2015-07-06 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>536</td>\n",
       "      <td>993.0</td>\n",
       "      <td>2017-09-11 00:00:00</td>\n",
       "      <td>2018-05-28 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>537</td>\n",
       "      <td>995.0</td>\n",
       "      <td>2016-09-05 00:00:00</td>\n",
       "      <td>2018-05-28 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>538</td>\n",
       "      <td>998.0</td>\n",
       "      <td>2017-12-04 00:00:00</td>\n",
       "      <td>2018-05-28 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>539 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index   user                  min                  max\n",
       "0        0    1.0  2015-06-29 00:00:00  2018-05-28 00:00:00\n",
       "1        1    3.0  2018-03-05 00:00:00  2018-04-23 00:00:00\n",
       "2        2    5.0  2017-06-05 00:00:00  2018-05-28 00:00:00\n",
       "3        3    6.0  2016-12-05 00:00:00  2018-05-28 00:00:00\n",
       "4        4    9.0  2016-07-18 00:00:00  2018-05-28 00:00:00\n",
       "..     ...    ...                  ...                  ...\n",
       "534    534  991.0  2016-10-24 00:00:00  2016-10-24 00:00:00\n",
       "535    535  992.0  2015-02-09 00:00:00  2015-07-06 00:00:00\n",
       "536    536  993.0  2017-09-11 00:00:00  2018-05-28 00:00:00\n",
       "537    537  995.0  2016-09-05 00:00:00  2018-05-28 00:00:00\n",
       "538    538  998.0  2017-12-04 00:00:00  2018-05-28 00:00:00\n",
       "\n",
       "[539 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cutoff dates\n",
    "cutoff_dates = emails.groupby('user').week.agg(['min','max']).reset_index()\n",
    "\n",
    "cutoff_dates = cutoff_dates.reset_index()\n",
    "\n",
    "cutoff_dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리가 봤던 998번 회원은 2015년 2월 9일에 가입했지만 2017년 12월 4일부터 메일을 열기 시작했다!\n",
    "\n",
    "이제 처음 메일을 열기 전 데이터를 삭제하자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "for _, row in cutoff_dates.iterrows():\n",
    "  user        = row['user']\n",
    "  start_date  = row['min']\n",
    "  end_date    = row['max']\n",
    "  all_email.drop(all_email[all_email.user == user][all_email.week < start_date].index, inplace=True)\n",
    "  all_email.drop(all_email[all_email.user == user][all_email.week > end_date].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번에는 기부금을 주별로 취합해 이메일 반응과 상관관계를 알아봅시다.\n",
    "\n",
    "1. donation은 순간의 timestamp로 되어있으므로 주별로 취합(down sampling)\n",
    "2. 이번 주의 donation에 대한 예측 변수: donation 이전 주의 열람 email 개수\n",
    "3. 한 주에 여러번 기부하는 사람은 흔치 않으므로 기부 건수 = 기부자 수로 간주"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user   timestamp \n",
       "0.0    2015-03-30      25.0\n",
       "       2015-04-06       0.0\n",
       "       2015-04-13       0.0\n",
       "       2015-04-20       0.0\n",
       "       2015-04-27       0.0\n",
       "                      ...  \n",
       "995.0  2017-09-11       0.0\n",
       "       2017-09-18       0.0\n",
       "       2017-09-25       0.0\n",
       "       2017-10-02    1000.0\n",
       "998.0  2018-01-08      50.0\n",
       "Name: amount, Length: 32352, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 33\n",
    "donations.timestamp = pd.to_datetime(donations.timestamp)   # 문자열 -> 시계열\n",
    "\n",
    "donations.set_index('timestamp', inplace=True) \n",
    "\n",
    "# '주'를 월요일로 고정한 후 재배정 -> 이메일 주간 날짜 데이터와 일치 시키기\n",
    "agg_don = donations.groupby('user').apply(lambda df: df.amount.resample(\"W-MON\").sum().dropna())\n",
    "\n",
    "agg_don"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>week</th>\n",
       "      <th>emailsOpened</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2015-06-29 00:00:00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2015-07-06 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2015-07-13 00:00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2015-07-20 00:00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2015-07-27 00:00:00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user                 week  emailsOpened  amount\n",
       "0   1.0  2015-06-29 00:00:00           3.0     NaN\n",
       "1   1.0  2015-07-06 00:00:00           0.0     NaN\n",
       "2   1.0  2015-07-13 00:00:00           2.0     NaN\n",
       "3   1.0  2015-07-20 00:00:00           2.0     NaN\n",
       "4   1.0  2015-07-27 00:00:00           3.0     NaN"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = pd.DataFrame()\n",
    "\n",
    "for user, user_email in all_email.groupby('user'):\n",
    "    ## 특정 회원의 기부 데이터 추출\n",
    "    user_donations = agg_don[agg_don.index.get_level_values('user') == user]\n",
    "  \n",
    "    ## 기부 데이터 인덱스를 timestamp로 설정\n",
    "    user_donations = user_donations.droplevel(0)\n",
    "    # user_donations.set_index('timestamp', inplace = True)  \n",
    "  \n",
    "    user_email = all_email[all_email.user == user]\n",
    "    user_email.sort_values('week', inplace=True)\n",
    "    user_email.set_index('week', inplace=True)\n",
    "\n",
    "    df = pd.merge(user_email, user_donations, how='left', left_index=True, right_index=True)\n",
    "    df.fillna(0)\n",
    "\n",
    "    merged_df = merged_df.append(df.reset_index()[['user', 'week', 'emailsOpened', 'amount']])\n",
    "\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>week</th>\n",
       "      <th>emailsOpened</th>\n",
       "      <th>amount</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>998.0</td>\n",
       "      <td>2017-12-04 00:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>998.0</td>\n",
       "      <td>2017-12-11 00:00:00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>998.0</td>\n",
       "      <td>2017-12-18 00:00:00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>998.0</td>\n",
       "      <td>2017-12-25 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>998.0</td>\n",
       "      <td>2018-01-01 00:00:00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>998.0</td>\n",
       "      <td>2018-01-08 00:00:00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>998.0</td>\n",
       "      <td>2018-01-15 00:00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user                 week  emailsOpened  amount  target\n",
       "0  998.0  2017-12-04 00:00:00           1.0     0.0     0.0\n",
       "1  998.0  2017-12-11 00:00:00           3.0     0.0     0.0\n",
       "2  998.0  2017-12-18 00:00:00           3.0     0.0     0.0\n",
       "3  998.0  2017-12-25 00:00:00           0.0     0.0     0.0\n",
       "4  998.0  2018-01-01 00:00:00           3.0     0.0     0.0\n",
       "5  998.0  2018-01-08 00:00:00           3.0     0.0     0.0\n",
       "6  998.0  2018-01-15 00:00:00           2.0     0.0     0.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 998번 회원만 고르기\n",
    "\n",
    "df = merged_df[merged_df.user == 998]\n",
    "\n",
    "## .shift(n): amount 열의 기록을 뒤로 n만큼 미룬다.\n",
    "df['target'] = df.amount.shift(1)\n",
    "df = df.fillna(0)\n",
    "df.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Timestamp의 문제\n",
    "\n",
    "#### 2.3.1 timestamp 자체는 유용하지만 다루기 매우 어렵다.\n",
    "\n",
    "- 무엇에 관한 timestamp인지 알기 어렵다.\n",
    "    - 생성 과정\n",
    "    - 생성 방법\n",
    "    - 생성 시기\n",
    "\n",
    "어느날 식단 기록 어플리케이션에 모두 같은 시간에 샐러드, 디톡스 주스, 현미밥과 각종 반찬을 기록했다면 한 끼에 먹은걸까? 하루 종일 먹은걸까? 어느 지역 기준의 시간인지도 모호하다. 이 데이터베이스를 설계하지 않았기 때문에 연구자는 timestamp의 생성 과정, 방법, 시기가 정해지는 매커니즘을 알기 어렵다. 가장 쉬운 방법은 정보 수집 코드를 모두 해석하거나, 코드를 작성한 사람에게 묻는 작업이다.\n",
    "\n",
    "#### 2.3.2 timestamp를 추측해 데이터 이해하기\n",
    "몇가지 추론에 도움이 되는 프로세스는 다음과 같다.\n",
    "1. timestamp에 대한 가설 세우기: 동일하거나, 이례적 패턴 파악\n",
    "2. 가설 시험: 현지 시간인지 표준 시간인지, 시간이 사용자의 행동을 반영하는지 외부 제약을 반영하는지 등\n",
    "\n",
    "\n",
    "- **현지시간? 표준시간?**\n",
    "    - 현지시간: 말 그대로 현지 시간. 하루 위주의 패턴 존재.\n",
    "    - 협정 세계시간Coordinated Universal Time(UTC): 빈번한 사용 요일, 시간을 파악해 절대적 시간에 기반한 추론. 2시 7시 14시에 식사했다는 데이터라면 예컨대 7시, 12시, 19시에 식사했다고 추측할 수 있음.\n",
    "\n",
    "- **dt**: 시간 차이를 의미. 각 사용자의 시간대를 추정할 수 있는 특징feature. dt가 길다면 하루 중 밤 시간대를 추측할 수 있음. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## dt 구하는 예시\n",
    "# df['dt'] = df.time - df.time.shift(-1)\n",
    "\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. 데이터 정리\n",
    "- 결측치: \n",
    "    - 대치법: 전체 관측에 기반해 누락 데이터 채워 넣기\n",
    "    - 보간법: 대치법의 일종. 인접 데이터를 사용해 누락 데이터 추정\n",
    "    - 삭제: 누락 데이터를 사용하지 않는 방법\n",
    "- 시계열 빈도 변경: 업샘플링, 다운 샘플링\n",
    "- 데이터 평활\n",
    "- 데이터 계절적 변동 문제 해결\n",
    "- 의도치 않은 사전관찰 방지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.3. 지수 평활Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "air = pd.read_csv('C:/Users/jung6/Downloads/AirPassengers.csv', parse_dates = True, header = None)\n",
    "air.columns = ['Date', 'Passengers']\n",
    "\n",
    "## thanks to Mark Wilson for this code correction\n",
    "## ewm: 다양한 감쇠요인 적용\n",
    "air['Smooth.5'] = air.ewm(alpha=0.5).mean().Passengers\n",
    "air['Smooth.1'] = air.ewm(alpha=0.1,).mean().Passengers\n",
    "air['Smooth.9'] = air.ewm(alpha=0.9,).mean().Passengers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Passengers</th>\n",
       "      <th>Smooth.5</th>\n",
       "      <th>Smooth.1</th>\n",
       "      <th>Smooth.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1949-01</td>\n",
       "      <td>112</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>112.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1949-02</td>\n",
       "      <td>118</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>115.157895</td>\n",
       "      <td>117.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1949-03</td>\n",
       "      <td>132</td>\n",
       "      <td>125.142857</td>\n",
       "      <td>121.372694</td>\n",
       "      <td>130.558559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1949-04</td>\n",
       "      <td>129</td>\n",
       "      <td>127.200000</td>\n",
       "      <td>123.590579</td>\n",
       "      <td>129.155716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1949-05</td>\n",
       "      <td>121</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>122.957974</td>\n",
       "      <td>121.815498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>1960-08</td>\n",
       "      <td>606</td>\n",
       "      <td>582.096411</td>\n",
       "      <td>468.874660</td>\n",
       "      <td>606.665454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>1960-09</td>\n",
       "      <td>508</td>\n",
       "      <td>545.048205</td>\n",
       "      <td>472.787195</td>\n",
       "      <td>517.866545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>1960-10</td>\n",
       "      <td>461</td>\n",
       "      <td>503.024103</td>\n",
       "      <td>471.608475</td>\n",
       "      <td>466.686655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>1960-11</td>\n",
       "      <td>390</td>\n",
       "      <td>446.512051</td>\n",
       "      <td>463.447626</td>\n",
       "      <td>397.668665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>1960-12</td>\n",
       "      <td>432</td>\n",
       "      <td>439.256026</td>\n",
       "      <td>460.302862</td>\n",
       "      <td>428.566867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  Passengers    Smooth.5    Smooth.1    Smooth.9\n",
       "0    1949-01         112  112.000000  112.000000  112.000000\n",
       "1    1949-02         118  116.000000  115.157895  117.454545\n",
       "2    1949-03         132  125.142857  121.372694  130.558559\n",
       "3    1949-04         129  127.200000  123.590579  129.155716\n",
       "4    1949-05         121  124.000000  122.957974  121.815498\n",
       "..       ...         ...         ...         ...         ...\n",
       "139  1960-08         606  582.096411  468.874660  606.665454\n",
       "140  1960-09         508  545.048205  472.787195  517.866545\n",
       "141  1960-10         461  503.024103  471.608475  466.686655\n",
       "142  1960-11         390  446.512051  463.447626  397.668665\n",
       "143  1960-12         432  439.256026  460.302862  428.566867\n",
       "\n",
       "[144 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "air"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "장기 추세 데이터에서 단순 지수평활은 제대로 예측하기 어렵다. 이를 보완하기 위해 홀트, 홀트-윈터스 평활, 칼만 필터, 국소추정산점도평활LOESS을 이용할 수 있다.\n",
    "\n",
    "- 홀트 메소드, 홀트-윈터스 평활: 추세를 가진 데이터, 추세와 계절성을 가진 데이터 모두에 적용할 수 있는 지수 평활 방법\n",
    "- 칼만 필터: 변동성 및 측정 오차의 조합으로 시계열 과정 모델링하여 데이터 평활\n",
    "- 국소추정산점도평활LOESS: 지역적으로 데이터를 평활하는 비모수적 방법. 복잡해지면서 계산 비용이 증가함. \n",
    "\n",
    "칼만 필터와 LOESS는 시간 전후 데이터를 모두 고려하므로 과거로 정보가 유출될 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 계절성 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 계절성: 특정 행동 빈도가 안정적으로 반복해서 나타나나는 것. 실제 계절도 포함되지만, 아침, 점심, 저녁 식사 또한 해당한다.\n",
    "\n",
    "산점도는 평균과 분산 증가를 알 수 있지만, 선 그래프는 계절 변동을 파악하기 쉽다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 계절성 데이터: 일련의 동작이 정해진 기간 동안 반복되는 시계열\n",
    "- 순환성 시계열: 반복적인 동작을 보이긴하지만, 기간이 가변적. 주식시장 호황, 불황은 불확실한 기간이지만 주기가 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> R에서 계절성seasonal, 추세trend, 나머지remainder가 포함된 그래프 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 시간대"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "시간대는 복잡하다.\n",
    "- 시간대는 정치, 사회적으로 형성\n",
    "- 언어 간, HTTP 프로토콜을 통해 표준 시간대 정볼르 전송하는 표준 방법이 없음\n",
    "- 시간대에 이름을 짓거나 일광 절약의 시작과 종료일을 결정하기 위한 단일화도니 프로토콜이 없음\n",
    "- 일광 절약으로 한 해에 몇 시간씩 시간 중복 발생"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파이썬은 자동 시간 검색 함수인 datetime.datetime.now()는 시간대를 인식하지 못함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2022, 5, 17, 11, 5, 46, 594072)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "import pytz\n",
    "\n",
    "datetime.datetime.utcnow()\n",
    "# datetime.datetime.utcnow()\n",
    "# datetime.datetime(2018, 5, 31, 14, 49, 43, 187680)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2022, 5, 17, 20, 5, 46, 756219)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "datetime.datetime.now()\n",
    "# >>> >>> datetime.datetime.now()\n",
    "# datetime.datetime(2018, 5, 31, 10, 49, 59, 984947)\n",
    "# as we can see, my computer does not return UTC even though there is no time zone attached\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2022, 5, 17, 11, 5, 47, 24462, tzinfo=datetime.timezone.utc)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "datetime.datetime.now(datetime.timezone.utc)\n",
    "# >>> datetime.datetime.now(datetime.timezone.utc)\n",
    "# datetime.datetime(2018, 5, 31, 14, 51, 35, 601355, tzinfo=datetime.timezone.utc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'US/Pacific'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# timezone 설정\n",
    "western = pytz.timezone('US/Pacific')\n",
    "western.zone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API를 통해 시간대를 인지한 시간을 생성하는 두가지 방법\n",
    "1. localize 이용\n",
    "2. 한 장소에서 다른 장소의 시간대로 변환하는 방식: pytz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2018, 5, 15, 12, 34, tzinfo=<DstTzInfo 'US/Pacific' PDT-1 day, 17:00:00 DST>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# localize\n",
    "loc_dt = western.localize(datetime.datetime(2018, 5, 15, 12, 34, 0))\n",
    "loc_dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "datetime 생성자에 시간대를 직접 전달하는 경우\n",
    "\n",
    "pytz를 사용하는 경우, 일광 절약이 없는 시간대에서만 원하는 결과를 얻을 수 있다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytz: 일광 절약이 영향을 줌\n",
    "london_tz = pytz.timezone('Europe/London')\n",
    "london_dt = loc_dt.astimezone(london_tz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2018, 5, 15, 20, 34, tzinfo=<DstTzInfo 'Europe/London' BST+1:00:00 DST>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "london_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2018-05-12 12:15:00 LMT-0001'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = '%Y-%m-%d %H:%M:%S %Z%z'\n",
    "datetime.datetime(2018, 5, 12, 12, 15, 0, tzinfo = london_tz).strftime(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 시간대를 계산하는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(days=1, seconds=17520)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# UTC형식으로 저장 후 출력할 때만 변환\n",
    "\n",
    "event1 = datetime.datetime(2018, 5, 12, 12, 15, 0, tzinfo = london_tz)\n",
    "event2 = datetime.datetime(2018, 5, 13, 9, 15, 0, tzinfo = western)\n",
    "event2 - event1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 연산은 잘못된 시간 간격을 계산한다. 각각 시간대가 london과 western으로 다르게 레이블링 되어있기 때문이다.\n",
    "\n",
    "아래는 localize를 통해 현지화했으므로 유효하다. 위의 연산과 값도 다른 것을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(days=1, seconds=18000)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# localize 후 계산하는 경우\n",
    "event1 = london_tz.localize( datetime.datetime(2018, 5, 12, 12, 15, 0))\n",
    "event2 = western.localize(datetime.datetime(2018, 5, 13, 9, 15, 0))\n",
    "event2 - event1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(days=1, seconds=18000)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# localize + UTC 변환\n",
    "event1 = london_tz.localize((datetime.datetime(2018, 5, 12, 12, 15, 0))).astimezone(datetime.timezone.utc)\n",
    "event2 = western.localize(datetime.datetime(2018, 5, 13, 9, 15, 0)).astimezone(datetime.timezone.utc)\n",
    "event2 - event1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**pytz**: pytz는 국가별 시간대와 일반 시간대 목록을 제공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 시간대 출력\n",
    "pytz.common_timezones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Europe/Kaliningrad',\n",
       " 'Europe/Moscow',\n",
       " 'Europe/Kirov',\n",
       " 'Europe/Astrakhan',\n",
       " 'Europe/Volgograd',\n",
       " 'Europe/Saratov',\n",
       " 'Europe/Ulyanovsk',\n",
       " 'Europe/Samara',\n",
       " 'Asia/Yekaterinburg',\n",
       " 'Asia/Omsk',\n",
       " 'Asia/Novosibirsk',\n",
       " 'Asia/Barnaul',\n",
       " 'Asia/Tomsk',\n",
       " 'Asia/Novokuznetsk',\n",
       " 'Asia/Krasnoyarsk',\n",
       " 'Asia/Irkutsk',\n",
       " 'Asia/Chita',\n",
       " 'Asia/Yakutsk',\n",
       " 'Asia/Khandyga',\n",
       " 'Asia/Vladivostok',\n",
       " 'Asia/Ust-Nera',\n",
       " 'Asia/Magadan',\n",
       " 'Asia/Sakhalin',\n",
       " 'Asia/Srednekolymsk',\n",
       " 'Asia/Kamchatka',\n",
       " 'Asia/Anadyr']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 국가별 시간대 출력\n",
    "pytz.country_timezones('RU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Europe/Paris']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 프랑스의 시간대 확인\n",
    "pytz.country_timezones('fr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 일광절약을 고려하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2002, 10, 27, 2, 30, tzinfo=<DstTzInfo 'US/Pacific' PST-1 day, 16:00:00 STD>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 시간대\n",
    "ambig_time = western.localize(datetime.datetime(2002, 10, 27, 1, 30, 00)).astimezone(datetime.timezone.utc)\n",
    "ambig_time_earlier = ambig_time - datetime.timedelta(hours=1)\n",
    "ambig_time_later = ambig_time + datetime.timedelta(hours=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2002, 10, 27, 1, 30, tzinfo=<DstTzInfo 'US/Pacific' PDT-1 day, 17:00:00 DST>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 초기\n",
    "ambig_time_earlier.astimezone(western)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2002, 10, 27, 1, 30, tzinfo=<DstTzInfo 'US/Pacific' PST-1 day, 16:00:00 STD>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 중기\n",
    "ambig_time.astimezone(western)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2002, 10, 27, 2, 30, tzinfo=<DstTzInfo 'US/Pacific' PST-1 day, 16:00:00 STD>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 후기\n",
    "ambig_time_later.astimezone(western)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "중기와 후기가 동일하다! 이 경우 is_dst를 통해 일광 절약 여부를 표시해야한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is_dst로 일광 절약 여부 확인\n",
    "ambig_time = western.localize(datetime.datetime(2002, 10, 27, 1, 30, 00), is_dst = True).astimezone(datetime.timezone.utc)\n",
    "ambig_time_earlier = ambig_time - datetime.timedelta(hours=1)\n",
    "ambig_time_later = ambig_time + datetime.timedelta(hours=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2002, 10, 27, 0, 30, tzinfo=<DstTzInfo 'US/Pacific' PDT-1 day, 17:00:00 DST>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ambig_time_earlier.astimezone(western)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2002, 10, 27, 1, 30, tzinfo=<DstTzInfo 'US/Pacific' PDT-1 day, 17:00:00 DST>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ambig_time.astimezone(western)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2002, 10, 27, 1, 30, tzinfo=<DstTzInfo 'US/Pacific' PST-1 day, 16:00:00 STD>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ambig_time_later.astimezone(western)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7 사전관찰 방지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사전관찰을 기계적으로 확인할 수는 없다. 끊임 없이 고민하고 경계하는 수 밖에 없다. 평활, 대치, 업 샘플링, 밀고 당김을 할 때마다 해도 되는지, 할 수 있는지, 그 결과가 무엇인지 고민해야한다. 다음은 점검 목록이다.\n",
    "\n",
    "1. 누락 데이터 대치, 평활할 때 사전 관찰 도입이 결과에 어떤 영향을 끼치는지 고민 및 확인할 것\n",
    "2. 작은 데이터셋으로 처리의 전체 공정을 구축해보기\n",
    "3. 각 종류의 데이터셋에 대해 타임스탬프와 관련된 지연 확인. 타임스탬프가 업로드 시점이 아니라 발생 시점에 저장되었는지 등을 파악해야 함.\n",
    "4. 시간을 인식할 수 있는 에러(롤링) 검사 또는 교차 검증 사용 ->11장\n",
    "5. 의도적으로 사전 관찰 도입하여 모델 관찰. -> 감 익히기\n",
    "6. 피처를 추가하면서 성능 향상 관찰. 사전 관찰일 경우 특정 피처가 특별한 이유 없이 매우 좋을 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e4cce46d6be9934fbd27f9ca0432556941ea5bdf741d4f4d64c6cd7f8dfa8fba"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
